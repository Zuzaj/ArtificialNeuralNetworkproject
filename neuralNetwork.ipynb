{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DGP2_lU32P86"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sigm(x):\n",
        "    return 1/(1+math.exp(-x))\n",
        "\n",
        "def sigm_delta(x):\n",
        "    return sigm(x)*(1-sigm(x))\n",
        "\n",
        "def softmax(nets):\n",
        "    max_net = max(nets)\n",
        "    exp_nets = [math.exp(net - max_net) for net in nets]\n",
        "    sum_exp_nets = sum(exp_nets)\n",
        "    softmax_values = [i / sum_exp_nets for i in exp_nets]\n",
        "    return softmax_values\n",
        "\n",
        "def oneHotEncoder(predictions_, dataset):\n",
        "      output = []\n",
        "      max_value = max(predictions_)\n",
        "      index = predictions_.index(max_value)\n",
        "      if dataset == 'digits':\n",
        "        for i in range(len(predictions_)):\n",
        "            if i == index:\n",
        "              output.append(1.0)\n",
        "            else:\n",
        "              output.append(0.0)\n",
        "      if dataset == 'xor':\n",
        "        if predictions_[0]>=0.5:\n",
        "            output = [0.0, 1.0]\n",
        "        else:\n",
        "            output = [1.0, 0.0]\n",
        "      return output\n"
      ],
      "metadata": {
        "id": "euHKPoHq2eFn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        #matrix of output weights for each neuron\n",
        "        self.outputs = []"
      ],
      "metadata": {
        "id": "ZLPJZZUw2WcK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InputLayer(Layer):\n",
        "    def __init__(self, inputs=[]):\n",
        "        super().__init__()\n",
        "\n",
        "        #for first layer output weights are equal to the input\n",
        "        self.outputs = inputs\n",
        "\n",
        "        #first layer has # of neurons equal to the size of our input\n",
        "        self.neurons_num = len(inputs)\n",
        "\n",
        "        print(f\"First layer added. It has {self.neurons_num} neurons\")"
      ],
      "metadata": {
        "id": "w4QisJhM2ZoN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HiddenLayer(Layer):\n",
        "    def __init__(self, neurons_num):\n",
        "        super().__init__()\n",
        "        self.nets = []\n",
        "        self.deltas = []\n",
        "        self.delta_w = []\n",
        "        self.weights = []\n",
        "        self.neurons_num = neurons_num\n",
        "\n",
        "    def backpropagation(self, next_layer):\n",
        "        for j in range(self.neurons_num):\n",
        "            self.deltas[j] = sum(next_layer.weights[i][j+1]*next_layer.deltas[i] for i in range(next_layer.neurons_num)) * sigm_delta(self.nets[j])\n",
        "\n",
        "\n",
        "    def propagateInputs(self, prev_layer, layers, dataset):\n",
        "        for j in range(self.neurons_num):\n",
        "            self.nets[j] = self.weights[j][0] + np.dot(self.weights[j][1:],prev_layer.outputs)\n",
        "            if(prev_layer != layers[-2] or dataset == 'xor'):\n",
        "              self.outputs[j] = sigm(self.nets[j])\n",
        "        #for digits dataset we need softmax as activation function for output layer\n",
        "        if(prev_layer == layers[-2] and dataset == 'digits'):\n",
        "          self.outputs = softmax(self.nets).copy()\n",
        "\n",
        "\n",
        "\n",
        "    def accumulateChange(self, prev_layer):\n",
        "        for j in range(self.neurons_num):\n",
        "            for i in range(1, prev_layer.neurons_num+1):\n",
        "                self.delta_w[j][i] += self.deltas[j]*prev_layer.outputs[i-1]\n",
        "            self.delta_w[j][0] = self.delta_w[j][0] + self.deltas[j]\n",
        "\n",
        "\n",
        "    def adjustWeights(self, prev_layer, lr, u):\n",
        "        for j in range(self.neurons_num):\n",
        "            for i in range(1, prev_layer.neurons_num+1):\n",
        "                self.weights[j][i] = self.weights[j][i] - lr*self.delta_w[j][i] - u*lr*self.delta_w[j][i]\n",
        "            self.weights[j][0] -= (lr * self.delta_w[j][0] + u*lr*self.delta_w[j][0])\n",
        "\n"
      ],
      "metadata": {
        "id": "G7S4frFb2jSZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class NeuralNetwork:\n",
        "\n",
        "    def __init__(self, inputs, real_outputs, layers_num, neurons_per_layer=[]):\n",
        "        #matrix of patterns\n",
        "        self.inputs = inputs\n",
        "        #matrix of real outputs\n",
        "        self.outputs = real_outputs\n",
        "        self.layers = []\n",
        "        #predicted output weights for current pattern\n",
        "        self.output = []\n",
        "        #real output for current pattern\n",
        "        self.d = []\n",
        "        self.layers_num = layers_num\n",
        "        self.neurons_per_layer = neurons_per_layer\n",
        "        print(\"Neurons per layer:\" , self.neurons_per_layer[0])\n",
        "\n",
        "        #initialization of network with first pattern\n",
        "        self.layers.append(InputLayer(self.inputs[0]))\n",
        "        print(f\"Layer 0 output: {self.layers[0].outputs}\")\n",
        "\n",
        "        #adding hidden layers with desired # of neurons per layer\n",
        "        for i in range(1, layers_num):\n",
        "            self.add(HiddenLayer(neurons_per_layer[i]))\n",
        "            print(f\"Added Hidden: {neurons_per_layer[i]} neurons\")\n",
        "\n",
        "\n",
        "    def add(self, layer: Layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def init_weights(self):\n",
        "        #for each layer except the InputLayer\n",
        "        for h in range(1, len(self.layers)):\n",
        "        #for each neuron\n",
        "            for i in range(self.layers[h].neurons_num):\n",
        "                #number of weights is equal to number of neurons in previous layer + 1 for bias\n",
        "                initial_weights = [random.uniform(-1, 1) for _ in range(self.layers[h-1].neurons_num+1)]\n",
        "                self.layers[h].weights.append(initial_weights)\n",
        "                self.layers[h].delta_w.append(np.zeros(self.layers[h-1].neurons_num+1))\n",
        "                self.layers[h].deltas.append(np.zeros(1))\n",
        "                self.layers[h].nets.append(np.zeros(1))\n",
        "                self.layers[h].outputs.append(np.zeros(1))\n",
        "\n",
        "\n",
        "    def backpropagateError(self):\n",
        "        #network output are the output weights of last layer\n",
        "        self.output = self.layers[-1].outputs\n",
        "        for j in range(self.layers[-1].neurons_num):\n",
        "          if self.dataset == 'xor':\n",
        "            #derivatives for sigmoid function\n",
        "            self.layers[-1].deltas[j] = -(self.d[j] - self.output[j]) * sigm_delta(self.layers[-1].nets[j])\n",
        "          if self.dataset == 'digits':\n",
        "            #derivatives for sotfmax function\n",
        "            self.layers[-1].deltas[j] = 0\n",
        "            for i in range(self.layers[-1].neurons_num):\n",
        "              if i != j:\n",
        "                self.layers[-1].deltas[j] -= (self.d[i] - self.output[i])*self.output[j]*(-self.output[i])\n",
        "              else:\n",
        "                self.layers[-1].deltas[j] -= (self.d[i] - self.output[i])*self.output[j]*(1 - self.output[i])\n",
        "\n",
        "        for h in range(len(self.layers)-2, 0, -1):\n",
        "            self.layers[h].backpropagation(self.layers[h+1])\n",
        "\n",
        "    def forward(self):\n",
        "        for h in range(1,len(self.layers)):\n",
        "            self.layers[h].propagateInputs(self.layers[h-1], self.layers, self.dataset)\n",
        "\n",
        "\n",
        "    def Change(self):\n",
        "        for h in range(1, len(self.layers)):\n",
        "            self.layers[h].accumulateChange(self.layers[h-1])\n",
        "\n",
        "    def Weights(self, lr, u):\n",
        "        for h in range(1, len(self.layers)):\n",
        "            self.layers[h].adjustWeights(self.layers[h-1], lr, u)\n",
        "\n",
        "    def feed_input(self, input, output):\n",
        "        self.layers[0].outputs = input\n",
        "        self.d = output\n",
        "        for h in range(1, len(self.layers)):\n",
        "            for i in range(self.layers[h].neurons_num):\n",
        "                self.layers[h].delta_w[i] = np.zeros(len(self.layers[h-1].outputs)+1)\n",
        "\n",
        "    def train(self, epochs, lr, u, dataset):\n",
        "        self.dataset = dataset\n",
        "        predicted_final = []\n",
        "        for n in range(epochs):\n",
        "            predictions = [[0.0] * len(self.outputs[0]) for _ in range(len(self.inputs))]\n",
        "            index_list = [j for j in range(len(self.inputs))]\n",
        "            while(index_list):\n",
        "                i = random.choice(index_list)\n",
        "                self.feed_input(self.inputs[i], self.outputs[i])\n",
        "                self.forward()\n",
        "                self.backpropagateError()\n",
        "                self.Change()\n",
        "                self.Weights(lr, u)\n",
        "                outs = self.output.copy()\n",
        "                outs = oneHotEncoder(outs, self.dataset)\n",
        "                predictions[i] = outs.copy()\n",
        "                index_list.remove(i)\n",
        "\n",
        "            print(f\"Accuracy for epoch {n}: {accuracy_score(self.outputs, predictions)}\")\n",
        "            if n == epochs-1:\n",
        "              predicted_final = predictions.copy()\n",
        "        print(\"Training successful\")\n",
        "        return predicted_final\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, pattern):\n",
        "        self.layers[0].outputs = pattern\n",
        "        self.forward()\n",
        "        output = self.layers[-1].outputs.copy()\n",
        "        output = oneHotEncoder(output, self.dataset)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-1JOpxq56x8q"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from csv import reader\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        #read first line\n",
        "        # k - inputs\n",
        "        # J - outputs\n",
        "        # N - patterns\n",
        "        k, J, N = map(int, file.readline().split())\n",
        "\n",
        "        inputs = []\n",
        "        outputs = []\n",
        "\n",
        "        # read N patterns\n",
        "        for _ in range(N):\n",
        "            line = file.readline().split()\n",
        "\n",
        "            pattern_inputs = list(map(float, line[:k]))\n",
        "            pattern_outputs = list(map(float, line[k:]))\n",
        "\n",
        "            inputs.append(pattern_inputs)\n",
        "            outputs.append(pattern_outputs)\n",
        "\n",
        "    return inputs, outputs"
      ],
      "metadata": {
        "id": "3C7lpPT3w8ky"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_digits, out_digits = load_dataset('train_digits.dat')\n",
        "\n",
        "\n",
        "#overview of out dataset\n",
        "\n",
        "print(\"Pattern lenght: \", len(in_digits[0]))\n",
        "print(\"Number of patterns: \", len(out_digits))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey_v32tew-mw",
        "outputId": "e0bc9712-63e1-4e73-d049-f2f44ff25df6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pattern lenght:  256\n",
            "Number of patterns:  1274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "neurons_num =  [256, 128, 64, 32, 10]\n",
        "\n",
        "model = NeuralNetwork(in_digits, out_digits, 5, neurons_num)\n",
        "model.init_weights()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb1CBCCExqEr",
        "outputId": "1b5fa7fa-3684-4b8f-e96f-166c3ecb0bb8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neurons per layer: 256\n",
            "First layer added. It has 256 neurons\n",
            "Layer 0 output: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Added Hidden: 128 neurons\n",
            "Added Hidden: 64 neurons\n",
            "Added Hidden: 32 neurons\n",
            "Added Hidden: 10 neurons\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_digits = model.train(9, 0.8, 0.01, 'digits')"
      ],
      "metadata": {
        "id": "mtyt9yIDzgfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05871bd3-9b58-4ef4-f7b9-fe757491d051"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for epoch 0: 0.3893249607535322\n",
            "Accuracy for epoch 1: 0.6962323390894819\n",
            "Accuracy for epoch 2: 0.8084772370486656\n",
            "Accuracy for epoch 3: 0.8744113029827315\n",
            "Accuracy for epoch 4: 0.8893249607535322\n",
            "Accuracy for epoch 5: 0.9262166405023547\n",
            "Accuracy for epoch 6: 0.9215070643642073\n",
            "Accuracy for epoch 7: 0.9167974882260597\n",
            "Accuracy for epoch 8: 0.9411302982731554\n",
            "Training successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for test set\n",
        "#optimal accuracy for 9 epochs\n",
        "\n",
        "in_digits_test, out_digits_test = load_dataset('test_digits.dat')\n",
        "\n",
        "pred_digits = []\n",
        "\n",
        "\n",
        "for pattern in in_digits_test:\n",
        "    output = model.predict(pattern)\n",
        "    pred_digits.append(output.copy())\n",
        "\n"
      ],
      "metadata": {
        "id": "E87Qvs7TYBql"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy for train set:\", accuracy_score(out_digits, predictions_digits))\n",
        "print(\"Accuracy for test set:\", accuracy_score(out_digits_test, pred_digits))\n",
        "\n",
        "#łiii"
      ],
      "metadata": {
        "id": "S2WlmpQoBMnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af042a17-8a0e-48a0-fd2d-1cf58dc1c261"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for train set: 0.9411302982731554\n",
            "Accuracy for test set: 0.890282131661442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_xor, out_xor = load_dataset('train_xor.dat')\n",
        "\n",
        "print(len(in_xor[0]))\n",
        "print(len(out_xor))\n",
        "\n",
        "neurons_num =  [2, 2, 1]\n",
        "\n",
        "model_xor = NeuralNetwork(in_xor, out_xor, 3, neurons_num)\n",
        "model_xor.init_weights()\n",
        "\n"
      ],
      "metadata": {
        "id": "oYeEXXOhn5ja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce6e742-8c90-4d98-fa8c-a20a63f17ddb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "4\n",
            "Neurons per layer: 2\n",
            "First layer added. It has 2 neurons\n",
            "Layer 0 output: [1.0, -1.0]\n",
            "Added Hidden: 2 neurons\n",
            "Added Hidden: 1 neurons\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_xor = model_xor.train(10, 0.9  , 0.05, 'xor')"
      ],
      "metadata": {
        "id": "Q6t_91b8pCv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa6f13a-c9c4-4a1e-9c3e-cdbae09d574d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for epoch 0: 0.5\n",
            "Accuracy for epoch 1: 0.5\n",
            "Accuracy for epoch 2: 0.5\n",
            "Accuracy for epoch 3: 0.5\n",
            "Accuracy for epoch 4: 0.5\n",
            "Accuracy for epoch 5: 0.5\n",
            "Accuracy for epoch 6: 0.75\n",
            "Accuracy for epoch 7: 0.75\n",
            "Accuracy for epoch 8: 0.5\n",
            "Accuracy for epoch 9: 1.0\n",
            "Training successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(accuracy_score(out_xor, predictions_xor))"
      ],
      "metadata": {
        "id": "UwJeUnM2pOe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6de0614-6d28-4bf9-d13c-2e6f498ab6c1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for test set\n",
        "\n",
        "in_xor_test, out_xor_test = load_dataset('test_xor.dat')\n",
        "\n",
        "pred_xor = []\n",
        "\n",
        "for pattern in in_xor_test:\n",
        "    output = model_xor.predict(pattern)\n",
        "    print(output)\n",
        "    pred_xor.append(output.copy())\n",
        "\n",
        "print(f\"Accuracy for train set: {accuracy_score(out_xor, predictions_xor)}\")\n",
        "print(f\"Accuracy for test set: {accuracy_score(out_xor_test, pred_xor)}\")"
      ],
      "metadata": {
        "id": "pjsKbsDvx-Yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74370a93-2e24-4cbe-dbbe-73413acf20ec"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 0.0]\n",
            "[1.0, 0.0]\n",
            "[1.0, 0.0]\n",
            "[0.0, 1.0]\n",
            "Accuracy for train set: 1.0\n",
            "Accuracy for test set: 0.75\n"
          ]
        }
      ]
    }
  ]
}